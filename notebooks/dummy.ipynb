{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dimensions need to be checked between n_users. n_items and X before calling this\n",
    "\"\"\"\n",
    "\n",
    "class Bias_Model(nn.Module):\n",
    "  \n",
    "    def __init__(self, n_users, n_items, nan_map, rand_init=True, max_bias=3, min_bias=0):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.user_bias = nn.Parameter(torch.zeros(n_users))\n",
    "        self.item_bias = nn.Parameter(torch.zeros(n_items))\n",
    "        self.nan_map = nan_map\n",
    "        if rand_init:\n",
    "            nn.init.uniform_(self.user_bias, min_bias, max_bias)\n",
    "            nn.init.uniform_(self.item_bias, min_bias, max_bias)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        y_pred = torch.cartesian_prod(self.user_bias, self.item_bias).sum(-1).view(len(self.user_bias), len(self.item_bias))\n",
    "        y_pred = torch.where(self.nan_map, torch.zeros_like(y_pred), y_pred)\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_v1(interaction_matrix, model, nan_map, epochs = 100, learning_rate = 1):\n",
    "    loss_arr = []\n",
    "    opt = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    X_train = torch.where(nan_map, torch.zeros_like(interaction_matrix), interaction_matrix)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        y_hat = model(X_train)\n",
    "        loss = F.mse_loss(y_hat, X_train)\n",
    "        loss_arr.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "\n",
    "    plt.plot(loss_arr, 'r-')\n",
    "    plt.show()      \n",
    "    print('Loss before training', loss_arr[0])\n",
    "    print('Loss after training', loss_arr[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with small handcrafted input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with dummy matrix\n",
    "train = torch.tensor([\n",
    "    [4, np.nan, np.nan, 3, 5, 3],\n",
    "    [np.nan, 1, 2, np.nan, 3, np.nan],\n",
    "    [4, np.nan, np.nan, 3, 4, 2],\n",
    "    [5, 1, 2, np.nan, 3, np.nan],\n",
    "    [4, np.nan, 3, 3, 5, 1]\n",
    "])\n",
    "\n",
    "nan_map = torch.isnan(train)\n",
    "n_users, n_items = train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bias_Model(n_users=n_users, n_items=n_items, nan_map=nan_map)\n",
    "fit_v1(interaction_matrix=train, nan_map=nan_map, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2 = Bias_Model(n_users=n_users, n_items=n_items, nan_map=nan_map, rand_init=False)\n",
    "fit_v1(interaction_matrix=train, nan_map=nan_map, model=model_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_v2.user_bias, model_v2.item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.user_bias, model.item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = torch.cartesian_prod(model.user_bias, model.item_bias).sum(-1).view(len(model.user_bias), len(model.item_bias))\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v2 = torch.cartesian_prod(model_v2.user_bias, model_v2.item_bias).sum(-1).view(len(model_v2.user_bias), len(model_v2.item_bias))\n",
    "final_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(nan_map, final, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(nan_map, final_v2, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with ratings only input from Amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mad_from_mean(arr):\n",
    "    mean_arr = np.array([np.mean(arr)]*len(arr))\n",
    "    return np.mean(abs(mean_arr - arr))\n",
    "\n",
    "\n",
    "def _enumerate_arr(value_count_series):\n",
    "    arr = np.empty(0)\n",
    "    for rating, occurence in zip(value_count_series.index, value_count_series.values):\n",
    "        arr = np.append(arr, [rating]*occurence)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def _get_unique_user_item_data(df):\n",
    "    unique_users, unique_items = len(df['u_id'].unique()), len(df['p_id'].unique())\n",
    "    return unique_users, unique_items, unique_users*unique_items\n",
    "\n",
    "\n",
    "def _get_unique_pairs_with_count(df):\n",
    "    result_df = df.groupby(['u_id','p_id']).size().reset_index().rename(columns={0:'count'})\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def _get_ratings_stats(counts_df, original_df):\n",
    "    same_ratings, diff_ratings = 0, 0\n",
    "    mad_arr = np.empty(0)\n",
    "    multi_rating_df = counts_df[counts_df['count']>1]\n",
    "    \n",
    "    for ind, row in multi_rating_df.iterrows():\n",
    "        temp = original_df[(original_df['u_id']==row['u_id']) & (original_df['p_id']==row['p_id'])]\n",
    "        if len(temp['rating'].value_counts()) > 1:\n",
    "            diff_ratings+=1\n",
    "            mad = _get_mad_from_mean(_enumerate_arr(temp['rating'].value_counts()))\n",
    "            mad_arr = np.append(mad_arr, mad)\n",
    "        else:\n",
    "            same_ratings+=1\n",
    "    print(mad_arr)\n",
    "    return len(multi_rating_df), same_ratings, diff_ratings, np.mean(mad_arr)\n",
    "\n",
    "\n",
    "def get_template_dict():\n",
    "    return {\n",
    "        'unique_users': np.nan,\n",
    "        'unique_items': np.nan,\n",
    "        'im_size': np.nan,\n",
    "        'unique_user_item_pairs': np.nan,\n",
    "        \"sparsity(unique_user_item_pairs/im_size x 100)\": np.nan,\n",
    "        'no_of_users_having_multiple_ratings': np.nan,\n",
    "        'same_ratings': np.nan,\n",
    "        'diff_ratings': np.nan,\n",
    "        'diff_mad': np.nan\n",
    "    }\n",
    "\n",
    "\n",
    "def get_report(file_name, folder_path):\n",
    "    stats_dict = get_template_dict()\n",
    "    df = pd.read_csv(folder_path+\"/\"+file_name, header=None, names=['u_id', 'p_id', 'rating'])\n",
    "    \n",
    "    stats_dict['unique_users'], stats_dict['unique_items'], stats_dict['im_size'] = _get_unique_user_item_data(df)\n",
    "    \n",
    "    counts_df = _get_unique_pairs_with_count(df=df)\n",
    "    stats_dict['unique_user_item_pairs'] = len(counts_df)\n",
    "    stats_dict[\"sparsity(unique_user_item_pairs/im_size x 100)\"] = (len(counts_df)/stats_dict['im_size'])*100\n",
    "    \n",
    "    stats_dict['no_of_users_having_multiple_ratings'],\\\n",
    "    stats_dict['same_ratings'], stats_dict['diff_ratings'],\\\n",
    "    stats_dict['diff_mad'] = _get_ratings_stats(counts_df=counts_df, original_df=df)\n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gift_Cards.csv', 'file_server/dataset/ratings/'), ('Pet_Supplies.csv', 'file_server/dataset/ratings/'), ('AMAZON_FASHION.csv', 'file_server/dataset/ratings/'), ('Patio_Lawn_and_Garden.csv', 'file_server/dataset/ratings/'), ('Books.csv', 'file_server/dataset/ratings/')]\n",
      "[0.5        0.5        0.5        0.44444444 0.5       ]\n",
      "[0.5        0.5        1.         0.5        0.5        0.5\n",
      " 1.5        0.5        1.         0.5        1.         1.5\n",
      " 0.375      0.44444444 1.         0.5        0.5        0.88888889\n",
      " 0.5        0.5        0.5        0.96       0.44444444 0.5\n",
      " 0.5        0.5        1.         1.         0.5        0.5\n",
      " 2.         1.5        0.5        0.5        0.5        1.33333333\n",
      " 0.5        0.5        0.5        1.         1.         0.5\n",
      " 0.5        2.         1.5        0.5        0.5        0.5\n",
      " 1.33333333 1.         0.5        1.         0.5        0.5\n",
      " 1.33333333 1.         0.5        1.         0.5        0.5\n",
      " 1.         0.5        0.5        2.         1.         2.\n",
      " 0.5        0.5        1.5        0.5        0.5        0.5\n",
      " 0.5        0.5        1.5        0.5        1.33333333 0.5\n",
      " 2.         0.5        0.5        0.5        0.5        1.5\n",
      " 0.88888889 1.         1.77777778 0.5        0.5        0.5\n",
      " 0.5        1.         0.44444444 2.         0.5        0.5\n",
      " 0.5        0.5        0.5        1.5        0.5        1.5\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        1.         1.         2.         0.5        0.5\n",
      " 0.5        0.5        1.5        1.5        0.44444444 1.11111111\n",
      " 1.         0.44444444 1.         0.5        0.5        1.\n",
      " 0.5        0.5        0.5        0.5        2.         0.5\n",
      " 0.5        0.5        1.5        0.5        0.5        2.\n",
      " 0.44444444 0.5        0.5        0.5        0.5        1.\n",
      " 0.5        0.5        1.         0.5        0.5        0.44444444\n",
      " 0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 1.         0.5        1.         0.5        0.5        0.5\n",
      " 1.         1.         0.5        1.5        0.5        1.\n",
      " 0.5        0.5        0.5        0.5        0.5        2.\n",
      " 1.         1.         0.5        1.         0.5        0.5\n",
      " 0.5        0.44444444 0.5        0.5        0.5        0.5\n",
      " 0.5       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-34:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-35:\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"file_server/dataset/ratings/\"\n",
    "#     files = os.listdir(folder_path)\n",
    "#     print(files)\n",
    "#     files = ['Magazine_Subscriptions.csv']\n",
    "    files = ['Gift_Cards.csv', 'Pet_Supplies.csv', 'AMAZON_FASHION.csv', 'Patio_Lawn_and_Garden.csv', 'Books.csv']\n",
    "    process_pool = multiprocessing.Pool(6)\n",
    "    data = list(zip(files, [folder_path]*len(files)))\n",
    "    print(data)\n",
    "    output = process_pool.starmap(get_report, data)\n",
    "    print(output)\n",
    "\n",
    "\n",
    "# t = pd.read_csv(folder+\"/Magazine_Subscriptions.csv\", header=None, names=['u_id', 'p_id', 'rating'])\n",
    "# temp_df = t.head(10)\n",
    "# temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unique_user_item_data(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = temp_df['rating'].value_counts()\n",
    "k, k.index, k.values, np.dot(k.index, k.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(temp_df['p_id'])\n",
    "dummies.values[dummies!=0] = temp_df['rating']\n",
    "dummies.replace(0, np.nan, inplace=True)\n",
    "dummies\n",
    "# l = pd.concat([temp_df['u_id'], pd.get_dummies()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = t.groupby(['u_id','p_id']).size().reset_index().rename(columns={0:'count'})\n",
    "print(len(pd.unique(t['u_id'])), len(pd.unique(t['p_id'])))\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_ratings, diff_ratings = 0, 0\n",
    "\n",
    "for ind, row in l[l['count']>1].iterrows():\n",
    "    temp = t[(t['u_id']==row['u_id']) & (t['p_id']==row['p_id'])]\n",
    "    if len(temp['rating'].value_counts()) > 1:\n",
    "        diff_ratings+=1\n",
    "    else:\n",
    "        same_ratings+=1\n",
    "    \n",
    "same_ratings, diff_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,\\\n",
    "b = 0, 0\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[l[\"count\"]>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_product([t.head(10)[0], t.head(10)[1]])\n",
    "pd.DataFrame(index = index).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"file_server/dataset/ratings/\"\n",
    "file_names = os.listdir(folder)\n",
    "for file_name in file_names:\n",
    "    temp_df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    a = np.random.randn(10000, 10000)\n",
    "    b = np.random.randn(10000, 10000)\n",
    "    c = np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    a = torch.randn(10000, 10000)\n",
    "    b = torch.randn(10000, 10000)\n",
    "    c = torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu():\n",
    "    if torch.cuda.device_count():\n",
    "        return torch.device('cuda:0')\n",
    "    return None\n",
    "\n",
    "gpu = get_gpu()\n",
    "gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([20, 1], requires_grad=True)\n",
    "y = 3*x - 2\n",
    "\n",
    "w = torch.tensor([1.], requires_grad=True)\n",
    "b = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "y_hat = w*x = b\n",
    "loss = torch.sum((y_hat - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(2,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3,4],[12,13,14,15]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_npy = df.values()\n",
    "\n",
    "df_tensors = torch.tensor(df.values)\n",
    "df_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = df_tensors.shape\n",
    "\n",
    "bi = torch.zeros(n_users)\n",
    "rj = torch.zeros(n_items)\n",
    "# provision for random initialization \n",
    " \n",
    "# create a map of present values\n",
    "rij = bi + rj\n",
    "loss = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tensors.sum(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_hat):\n",
    "    \"\"\"\n",
    "    Compute mean squared error\n",
    "    \"\"\"\n",
    "    return torch.mean((y - y_hat).pow(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0*np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.optim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_train = np.array([[4, np.nan, np.nan, 3, 5, 2],\n",
    "                        [np.nan, 1, 2, np.nan, 3, np.nan]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = torch.tensor(dummy_train)\n",
    "map_ = torch.isnan(tr)\n",
    "print(tr)\n",
    "print(map_)\n",
    "# tr[torch.isnan(tr)] = 0\n",
    "# tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(map_, torch.zeros_like(tr), tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = torch.tensor([[2,2,2,2,2,2], [4,4,4,4,4,4]], dtype=float)\n",
    "dd = torch.where(map_, torch.zeros_like(dd), dd)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3*torch.zeros(5) - 3*torch.rand(5)\n",
    "k.repeat(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "k = torch.zeros(5)\n",
    "init.uniform_(k, 4,5)\n",
    "k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2,3,4,5], dtype=float)\n",
    "b = torch.tensor([6, 10], dtype=float)\n",
    "\n",
    "def vector_cartesian_sum(x, y):\n",
    "    x_hat_transpose =  x.repeat(len(y)).view(len(y), len(x)).t()\n",
    "    y_hat = y.repeat(len(x)).view(len(x), len(y))\n",
    "    return torch.add(x_hat_transpose,y_hat)\n",
    "\n",
    "\n",
    "vector_cartesian_sum(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cartesian_prod(a,b).sum(-1).view(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
