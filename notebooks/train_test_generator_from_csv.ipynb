{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magazine category IM matrix dump\n",
    "* Load\n",
    "* transform to IM matrix with multiple ratings in a list\n",
    "* replace cells with mean of ratings\n",
    "* all empty cells with NaN\n",
    "* sample 20% of occupied cells\n",
    "* dump both train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"file_server/dataset/ratings\"\n",
    "files = [\"Magazine_Subscriptions.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder_path+\"/Magazine_Subscriptions.csv\", header=None, names=['u_id', 'p_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iteraction_matrix_with_mean_ratings(df):\n",
    "    k = pd.get_dummies(df['p_id'])\n",
    "    k.values[k!=0] = df['rating']\n",
    "    k.replace(0, np.nan, inplace=True)\n",
    "    k = pd.concat([df['u_id'], k], axis=1)\n",
    "    k = k.groupby('u_id').mean()\n",
    "    return np.array(k.index), np.array(k.columns), k.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18241 115\n"
     ]
    }
   ],
   "source": [
    "df = df.iloc[:20000, :]\n",
    "print(len(df['p_id'].unique()), len(df['u_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, interaction_matrix = get_iteraction_matrix_with_mean_ratings(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115,), (18241,), (115, 18241))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape, items.shape, interaction_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(115,) (18241,) (115, 18241)\n"
     ]
    }
   ],
   "source": [
    "## Drop products which have no ratings\n",
    "\n",
    "def get_products_with_no_ratings(s):\n",
    "    col_indices = list()\n",
    "    for i in range(s.shape[1]):\n",
    "        if np.count_nonzero(~np.isnan(s[:,i]))==0:\n",
    "            col_indices.append(i)\n",
    "    print(col_indices)\n",
    "    return col_indices\n",
    "\n",
    "col_to_remove = get_products_with_no_ratings(interaction_matrix)\n",
    "\n",
    "interaction_matrix = np.delete(interaction_matrix, col_to_remove, axis=1)\n",
    "items = np.delete(items, col_to_remove, axis=0)\n",
    "\n",
    "print(users.shape, items.shape, interaction_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19954\n",
      "0.9512255001275197\n"
     ]
    }
   ],
   "source": [
    "# sparsity\n",
    "values_present = np.count_nonzero(~np.isnan(interaction_matrix))\n",
    "print(values_present)\n",
    "print(values_present*100/(interaction_matrix.shape[0]*interaction_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_na_in_row(row, threshold):\n",
    "    n_ratings = np.count_nonzero(~np.isnan(row))\n",
    "    if  n_ratings >= threshold:\n",
    "        return n_ratings, 1\n",
    "    return n_ratings, 0\n",
    "\n",
    "index_counter = np.empty(0)\n",
    "ratings_per_user = np.empty(0)\n",
    "for row in interaction_matrix:\n",
    "    n_ratings, th_cleared = count_non_na_in_row(row, 5)\n",
    "    index_counter = np.append(index_counter, th_cleared)\n",
    "    ratings_per_user = np.append(ratings_per_user, n_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 173.51304347826087)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_counter, ratings_per_user.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train by copying interaction matrix\n",
    "train = np.copy(interaction_matrix)\n",
    "\n",
    "# create a nan filled test like train\n",
    "test = np.empty_like(train)\n",
    "test[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    \n",
    "    # sample only if index_counter values are 1, we dont want to sample and edit rows below the threshold\n",
    "    if index_counter[i] == 1:\n",
    "        \n",
    "        # get indices of non missing values in each row\n",
    "        non_nan_map = ~np.isnan(train[i])\n",
    "        non_nan_indices = [ind for ind,_ in enumerate(non_nan_map) if _]\n",
    "\n",
    "        # randomly sample 20% of non missing indices\n",
    "        sample = random.sample(non_nan_indices, math.ceil(0.2*len(non_nan_indices)))\n",
    "\n",
    "        # set these sampled indices ka value to test, and replace them with NaN in train\n",
    "        for k in sample:\n",
    "            test[i,k] = train[i,k]\n",
    "            train[i,k] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice test and users as per index_counter, which indicates the \n",
    "# map of users having more than \"threshold\" ratings\n",
    "\n",
    "users_of_interest = users[index_counter==1]\n",
    "test = test[index_counter==1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 18241) (107, 18241)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(184, 147, 37)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should result in 107 products, checking...\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "np.count_nonzero(~np.isnan(interaction_matrix[5])), np.count_nonzero(~np.isnan(train[5])), np.count_nonzero(~np.isnan(test[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_location = \"file_server/processed_data/iteration1/magazine_subscription_subset_115X18241/\"\n",
    "\n",
    "# dump training and test files\n",
    "\n",
    "with open(dump_location+\"train_matrix.pkl\", \"wb\")as fp:\n",
    "    dill.dump(train, fp)\n",
    "    \n",
    "with open(dump_location+\"train_users.pkl\", \"wb\")as fp:\n",
    "    dill.dump(users, fp)\n",
    "\n",
    "with open(dump_location+\"items.pkl\", \"wb\")as fp:\n",
    "    dill.dump(items, fp)\n",
    "\n",
    "with open(dump_location+\"test_matrix.pkl\", \"wb\")as fp:\n",
    "    dill.dump(test, fp)\n",
    "    \n",
    "with open(dump_location+\"test_users.pkl\", \"wb\")as fp:\n",
    "    dill.dump(users_of_interest, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scribble space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 147, 37)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(~np.isnan(interaction_matrix[5])), np.count_nonzero(~np.isnan(train[5])), np.count_nonzero(~np.isnan(test[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3937, 4395, 4479, 4939, 5240, 7593, 8117, 9283, 12531, 16511, 17000, 17381, 17863]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4395, 17863, 5240]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_nan_map = ~np.isnan(train[2])\n",
    "non_nan_indices = [ind for ind,_ in enumerate(non_nan_map) if _]\n",
    "print(non_nan_indices)\n",
    "\n",
    "import random, math\n",
    "random.sample(non_nan_indices, math.ceil(0.2*len(non_nan_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B00005N7NQ', 'B00005N7O6', 'B00005N7O9', 'B00005N7OA',\n",
       "       'B00005N7OC', 'B00005N7OD', 'B00005N7OF', 'B00005N7OP',\n",
       "       'B00005N7OU', 'B00005N7OV', 'B00005N7P0', 'B00005N7PG',\n",
       "       'B00005N7PH', 'B00005N7PI', 'B00005N7PN', 'B00005N7PS',\n",
       "       'B00005N7PT', 'B00005N7Q1', 'B00005N7Q2', 'B00005N7Q5',\n",
       "       'B00005N7QA', 'B00005N7QC', 'B00005N7QD', 'B00005N7QE',\n",
       "       'B00005N7QG', 'B00005N7QH', 'B00005N7QI', 'B00005N7QJ',\n",
       "       'B00005N7QL', 'B00005N7QN', 'B00005N7QO', 'B00005N7QS',\n",
       "       'B00005N7QW', 'B00005N7R0', 'B00005N7R5', 'B00005N7R6',\n",
       "       'B00005N7R7', 'B00005N7RA', 'B00005N7RD', 'B00005N7RF',\n",
       "       'B00005N7RJ', 'B00005N7RO', 'B00005N7RP', 'B00005N7RT',\n",
       "       'B00005N7RV', 'B00005N7S2', 'B00005N7S4', 'B00005N7S5',\n",
       "       'B00005N7S8', 'B00005N7SA', 'B00005N7SB', 'B00005N7SC',\n",
       "       'B00005N7SD', 'B00005N7SG', 'B00005N7SH', 'B00005N7SL',\n",
       "       'B00005N7SM', 'B00005N7SN', 'B00005N7SS', 'B00005N7SV',\n",
       "       'B00005N7T3', 'B00005N7T5', 'B00005N7T6', 'B00005N7T8',\n",
       "       'B00005N7TB', 'B00005N7TE', 'B00005N7TG', 'B00005N7TH',\n",
       "       'B00005N7TL', 'B00005N7TM', 'B00005N7TN', 'B00005N7TX',\n",
       "       'B00005N7U1', 'B00005N7UC', 'B00005N7UG', 'B00005N7UK',\n",
       "       'B00005N7UW', 'B00005N7VL', 'B00005N7VO', 'B00005N7VP',\n",
       "       'B00005N7VQ', 'B00005N7WA', 'B00005N7WP', 'B00005N7XF',\n",
       "       'B00005N7XG', 'B00005N7XI', 'B00005N7XO', 'B00005N7XQ',\n",
       "       'B00005N7XS', 'B00005NINB', 'B00005NIO6', 'B00005NIOC',\n",
       "       'B00005NIOH', 'B00005NIOM', 'B00005NION', 'B00005NIOP',\n",
       "       'B00005NIOR', 'B00005NIOW', 'B00005NIOZ', 'B00005NIP7',\n",
       "       'B00005NIPE', 'B00005NIPF', 'B00005NIPH', 'B00005NIPN',\n",
       "       'B00005NIPP', 'B00005NIQO', 'B00005NIRG'], dtype=object)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_var = interaction_matrix[:10, :100]\n",
    "temp_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(temp_var.shape[0])\n",
    "training_idx, test_idx = indices[:int(0.8*len(temp_var))], indices[int(0.8*len(temp_var)):]\n",
    "training, test = temp_var[training_idx,:], temp_var[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 100), (2, 100))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B00005N7O6', 'B00005N7OJ', 'B00005N7OC', 'B00005N7OP',\n",
       "       'B00005N7O9', 'B00005N7OA', 'B00005N7NQ', 'B00005N7OF'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_train, users_test = users[training_idx], users[test_idx]\n",
    "users_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/miniconda3/envs/rec_sys/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/bigdata/miniconda3/envs/rec_sys/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>p_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>AOSFI0JEYU4XM</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>AOSFI0JEYU4XM</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00005N7OJ</td>\n",
       "      <td>A3JPFWKS83R49V</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00005N7OJ</td>\n",
       "      <td>A19FKU6JZQ2ECJ</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>A25MDGOMZ2GALN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>A3XT9XXWXFMJ1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>A3ERU005ES1IHT</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>AC2278WPK3EU</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>A3QRR8PSCBI07C</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00005N7P0</td>\n",
       "      <td>A5QQOOZJOVPSF</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         u_id            p_id  rating\n",
       "0  B00005N7P0   AOSFI0JEYU4XM     4.0\n",
       "1  B00005N7P0   AOSFI0JEYU4XM     5.0\n",
       "2  B00005N7OJ  A3JPFWKS83R49V     3.0\n",
       "3  B00005N7OJ  A19FKU6JZQ2ECJ     5.0\n",
       "4  B00005N7P0  A25MDGOMZ2GALN     5.0\n",
       "5  B00005N7P0   A3XT9XXWXFMJ1     3.0\n",
       "6  B00005N7P0  A3ERU005ES1IHT     5.0\n",
       "7  B00005N7P0    AC2278WPK3EU     5.0\n",
       "8  B00005N7P0  A3QRR8PSCBI07C     4.0\n",
       "9  B00005N7P0   A5QQOOZJOVPSF     4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df.head(10).copy()\n",
    "temp_df['p_id'][0] = \"AOSFI0JEYU4XM\"\n",
    "temp_df['rating'][0] = 4\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['B00005N7OJ', 'B00005N7P0'], dtype=object),\n",
       " array(['A19FKU6JZQ2ECJ', 'A25MDGOMZ2GALN', 'A3ERU005ES1IHT',\n",
       "        'A3JPFWKS83R49V', 'A3QRR8PSCBI07C', 'A3XT9XXWXFMJ1',\n",
       "        'A5QQOOZJOVPSF', 'AC2278WPK3EU', 'AOSFI0JEYU4XM'], dtype=object),\n",
       " array([[5. , nan, nan, 3. , nan, nan, nan, nan, nan],\n",
       "        [nan, 5. , 5. , nan, 4. , 3. , 4. , 5. , 4.5]]),\n",
       "             A19FKU6JZQ2ECJ  A25MDGOMZ2GALN  A3ERU005ES1IHT  A3JPFWKS83R49V  \\\n",
       " u_id                                                                         \n",
       " B00005N7OJ             5.0             NaN             NaN             3.0   \n",
       " B00005N7P0             NaN             5.0             5.0             NaN   \n",
       " \n",
       "             A3QRR8PSCBI07C  A3XT9XXWXFMJ1  A5QQOOZJOVPSF  AC2278WPK3EU  \\\n",
       " u_id                                                                     \n",
       " B00005N7OJ             NaN            NaN            NaN           NaN   \n",
       " B00005N7P0             4.0            3.0            4.0           5.0   \n",
       " \n",
       "             AOSFI0JEYU4XM  \n",
       " u_id                       \n",
       " B00005N7OJ            NaN  \n",
       " B00005N7P0            4.5  )"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# k = pd.get_dummies(temp_df, columns=['p_id'], prefix='', prefix_sep='')\n",
    "\n",
    "# names = list(k.columns).pop(1)\n",
    "# print(names)\n",
    "# k.groupby(names).mean()\n",
    "# k\n",
    "# f = pd.get_dummies(k['p_id'])\n",
    "# f.values[f!=0] = k['rating']\n",
    "# f.values[f==0] = np.nan\n",
    "# f\n",
    "\n",
    "# # k = pd.get_dummies(temp_df, columns=['p_id'])\n",
    "k = pd.get_dummies(temp_df['p_id'])\n",
    "k.values[k!=0] = temp_df['rating']\n",
    "k.replace(0, np.nan, inplace=True)\n",
    "k\n",
    "k = pd.concat([temp_df['u_id'], k], axis=1)\n",
    "# # names = k.columns #- ['ratings']\n",
    "# # names\n",
    "j = k.groupby('u_id').mean()\n",
    "np.array(j.index), np.array(j.columns), j.values, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>p_id_A19FKU6JZQ2ECJ</th>\n",
       "      <th>p_id_A25MDGOMZ2GALN</th>\n",
       "      <th>p_id_A3ERU005ES1IHT</th>\n",
       "      <th>p_id_A3JPFWKS83R49V</th>\n",
       "      <th>p_id_A3QRR8PSCBI07C</th>\n",
       "      <th>p_id_A3XT9XXWXFMJ1</th>\n",
       "      <th>p_id_A5QQOOZJOVPSF</th>\n",
       "      <th>p_id_AC2278WPK3EU</th>\n",
       "      <th>p_id_AOSFI0JEYU4XM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00005N7OJ</th>\n",
       "      <td>4.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00005N7P0</th>\n",
       "      <td>4.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rating  p_id_A19FKU6JZQ2ECJ  p_id_A25MDGOMZ2GALN  \\\n",
       "u_id                                                           \n",
       "B00005N7OJ   4.000                  0.5                0.000   \n",
       "B00005N7P0   4.375                  0.0                0.125   \n",
       "\n",
       "            p_id_A3ERU005ES1IHT  p_id_A3JPFWKS83R49V  p_id_A3QRR8PSCBI07C  \\\n",
       "u_id                                                                        \n",
       "B00005N7OJ                0.000                  0.5                0.000   \n",
       "B00005N7P0                0.125                  0.0                0.125   \n",
       "\n",
       "            p_id_A3XT9XXWXFMJ1  p_id_A5QQOOZJOVPSF  p_id_AC2278WPK3EU  \\\n",
       "u_id                                                                    \n",
       "B00005N7OJ               0.000               0.000              0.000   \n",
       "B00005N7P0               0.125               0.125              0.125   \n",
       "\n",
       "            p_id_AOSFI0JEYU4XM  \n",
       "u_id                            \n",
       "B00005N7OJ                0.00  \n",
       "B00005N7P0                0.25  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(temp_df, columns=['p_id']).groupby(['u_id'], as_index=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import databricks.koalas as ks\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "def create_spark_context() -> SparkContext:\n",
    "    spark_conf = SparkConf().setMaster(\"spark://172.16.10.134:7077\").setAppName(\"Spark_processing\")\n",
    "    return SparkContext.getOrCreate(spark_conf) \n",
    "\n",
    " \n",
    "\n",
    "sc = create_spark_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    " \n",
    "\n",
    "def create_spark_context() -> SparkContext:\n",
    "    spark_conf = SparkConf()\\\n",
    "        .setMaster(\"spark://172.16.10.130:7077\")\\\n",
    "        .setAppName(\"Spark_Init_Test\")\\\n",
    "        .set(\"spark.executor.memory\", \"12g\")\n",
    "        #.set('spark.rpc.message.maxSize', 300)\\\n",
    "    return SparkContext.getOrCreate(spark_conf) \n",
    "\n",
    " \n",
    "\n",
    "sc = create_spark_context();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlcontext = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"file_server/dataset/ratings/\"\n",
    "#     files = os.listdir(folder_path)\n",
    "#     print(files)\n",
    "files = ['Magazine_Subscriptions.csv']\n",
    "\n",
    "df = pd.read_csv(folder_path+\"/\"+files[0], header=None, names=['u_id', 'p_id', 'rating'])\n",
    "sdf = sqlcontext.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.set_option('compute.default_index_type', 'distributed-sequence')\n",
    "\n",
    "kdf = sdf.to_koalas()\n",
    "kdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = kdf.head(10)\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = temp_df.groupby(['u_id','p_id']).size().reset_index().rename(columns={0:'count'})\n",
    "print(len(ks.unique(temp_df['u_id'])), len(ks.unique(temp_df['p_id'])))\n",
    "print(len(l))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
